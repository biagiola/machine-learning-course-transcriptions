WEBVTT <v Instructor>Welcome back everybody.</v> This is ML Experts, machine learning crash course. In this video, we're gonna be talking about recommender systems, and specifically we're gonna be going over collaborative and content filtering. So going back to the blind app example, where we now have all of these new content creators that were inspired by our chat box, how do we know which of their content goes to which user? In other words, let's say a particular post was gaining popularity and we wanted to evaluate if we should send a push notification to a particular user recommending that they read the post. The first thing we can consider is collaborative filtering. This matrix here is a user item matrix. In our case, it's a user post matrix. Items could be products or anything else. Each element here will either be a zero or one indicating that a particular user has read a particular post. So the goal of collaborative filtering is to use this user item matrix to get an idea of how a user would respond to an unseen piece of content such as a post or a video or a product. So let's look at this in more detail. Here we have user I liked post K will be a one. If the user has not seen a particular post, the entry will be zero. So a very simple thing that we can do is called user-based collaborative filtering. The goal is to find similar users. Here these users are pretty similar and recommend to some user here, user two a particular post if similar users also liked that post. Here, similarity will just be measured in Jaccard distance or Cosine similarity or Hamming distance. We've been over these metrics before, but let's go ahead and go over them again. Jaccard similarity will just have the number of matching ones in the numerator, the number of matching ones in the denominator, plus the mismatches Notice here that we're not including the case where there are matching zeros in the numerator or the denominator. So in the case of our two users, we have three matching ones, we have one spot where they don't match, and they have none of these, so the Jaccard similarity is .75. For Cosine similarity, we simply add up the product of the two and then we multiply the square roots of the sum of the entry squared. So here we'll have three in the numerator. We'll have the square root of four times the square root of three in the denominator. And the Cosine similarity between these two users will be .86 For Hamming distance, we simply sum up the differences. So here they're the same, which is zero, same zero. The only place where they differ is one. So the Hamming distance here will be one. Notice that here is distance instead of similarity. So in order to find the most similar users, you would make sure to minimize this distance instead of maximizing some similarity. So now that we've been over this user collaborative filtering approach, how do we know what to predict for this particular user? Even though that we found these two users similar, we still don't necessarily know how this user will respond. So the formula to predict this value is just this. So the response of user one will be equal to the summation of all of the users in which user I is a similar user, normalized by all of the similarities of the similar users. So in this case, if we used Cosine similarity, which we got .86, we only have to sum through one user. So there will only be one user in this numerator. So the similarity between these two were .86. So we have .86 times the response of user one, which was one, divided by the sum of all of the similarities, which is .86 So here, the predicted response of user two for this particular post is one. I think this prediction is pretty reasonable. So we can go ahead and put that one in now. Now, we only looked at two neighbors, but we can actually use the K nearest neighbors algorithm to figure out more neighbors if we want to form potentially better predictions. Now, let's say we wanted to incorporate more than just binary indicators. So let's instead model that users could rate particular post. So this user rated post one as maybe three stars. Here, zero will just mean that a user hasn't seen it, and the max rating is five stars. So now let's apply the same principle. So to gauge similarity of these users since we're no longer using binary indicators, we'll have to use different types of similarity metrics. This can be Euclidean, Manhattan, Pearson and Cosine as well. Now, we've been over Euclidean and Manhattan distances quite a bit, but let's go ahead and visit Pearson correlation. Pearson correlation can be derived from this formula here. So here, this is just the average rating of user one, this is the average rating of user two, and then we're summing across each one of their individual ratings. For the denominator, we do something similar, except we're just squaring the terms instead of multiplying them together. So here our two users would have the Pearson correlation of .93. An interesting use of Pearson correlation is that the optimism a user's ratings across all the different products is accounted for. So let's say that I was super pessimistic and I only rated things between one and three, even though that ratings four and five exists. And let's say another user was very optimistic and they rated everything as either four or five, this Pearson correlation will be able to adjust for these differences. So how do we use this Pearson correlation to form a prediction? The prediction formula is the same exact formula that we saw before in the binary case. To evaluate our predictions, we can use means squared error. This can be done through a validation set. So now we can go ahead and put in one for our predicted response by user two for post four. So in total for user based collaborative filtering, we find the K nearest neighbors of a particular user that we want to get a prediction for. We can use various similarity metrics like Jaccard, Pearson or Cosine, then using these similarity metrics and the data or ratings associated with each of those K nearest neighbors, we can form a predicted response for a particular user. Generally, we want to recommend the item for user I, which outputs the highest predicted value. Another approach to collaborative filtering is called item based. Here, we have some five users and two posts. What we do instead is we take the similarity between the products. So here, if we take the Cosine similarity of this user item matrix with respect to just the products, we will get something called the item-item similarity matrix. So how can we use this to predict user two's response to reading post one? Well, here's the formula. As you can see, it's pretty similar to the formula that we used for user-based collaborative filtering. So here we want to make a prediction for user two based on post one and post two. The Cosine similarity between post one and post two was .86. The way that user two responded to post two was positively, they liked it. So we'll put a one here. And then we just normalize by the sum of all of the similarities. And now we have the predicted response to user two seeing post one. We're assuming that they'll like it. Now, to evaluate the performance of these predictions, you can use a validation set and measure the mean squared error. So let's go over the process of item-based collaborative filtering. Step one is we calculate the item-item similarity matrix. Two, we predict the response for some particular user using this formula. Finally, we recommend the item with the highest prediction. So here's the time complexity of user based, and here's the time complexity of item based. Since these matrices are typically sparse, such that many users don't interact with many of the items, the time complexity in practice is typically this. Now, user based can provide greater diversity since we're not comparing products as much as we are users, so if a similar user to you like something very different from the items that you've liked, we can still recommend you those items because you were similar to the user, not necessarily similar to some post. The downside is that it's typically more expensive because you have to calculate the K nearest neighbors. For item based, even though that we have what appears to be a larger time complexity here, most of this work can be done offline. In practice, this just means that we would calculate that item-item similarity matrix beforehand. A benefit of item based is that there's typically less recalculations. This is usually because items themselves usually change less than users change. The problem is that we're going to lack diversity. This is the opposing result to what we saw as a benefit in the user-based collaborative filtering. Now, in case you hear it, both of these tactics exist under something called memory-based recommender systems. Now, some other things that you can do with these memory-based systems is one, we can apply a time decay. So here is our prediction formula. We can add a time decay to the user's response, such that the time decay is going to be influenced by some particular half-life. What this means is that as time goes on, less influence will be given to a particular rating. So here, if we plug in one for T, this equation will come out to be .87, which is what we'll multiply times the user's response. What that means is that this user's response since it's now weighted will mean less in the overall prediction. Here, if time is equal to five, that's actually our half-life, so the user's response will actually mean half as much as it originally did. This T here can be run for any timescale. So it can be for a day, for a month, for a year, it's really up to you. For our particular application, I prefer a smaller timescale such as a day or maybe a week. Another thing that we can do is apply more weight to less frequented items. So here we have a user's response to some product. We can multiply that by FI. Now, the formula for FI is exactly the same as we solved for inverse document frequency. So here we take the log of the total number of users, and we divide that by the number of users who interacted with the particular posts. This is sometimes called the inverse user frequency. What this does is it applies less weight to a particular response if that particular post is extremely popular. Likewise, if the post isn't as popular and this user still liked it, then we weight it more. So one problem with memory based approaches is that this user item matrix or this item-item similarity matrix is extremely large. One approach that we can use is called matrix factorization. Matrix factorization takes that same user item matrix that we saw before, and instead, it factorizes it into these terms. So what are these terms? Well, it's almost exactly the same as we had for linear regression. The only difference is that these two terms will have to both be learned, when in linear regression, only the weights had to be learned. Additionally, instead of just a single bias, we have a bias for the posts and a bias for the users. So if you recall, the loss for linear regression look like this, the loss for this matrix factorization looks like this. It's again, extremely similar. Now, for linear regression, we could also have regularizers in here by making sure that the weights stay reasonably small. We could also add regularizers for the bias. Here, we'll show the full regularizers for this matrix factorization. We have a regularizer for U, for P for the bias of U and for the bias of P. Again, this is L2 regularization. Another thing we'll add here is that we can use something called implicit ratings. So here, if we had some binary user item matrix, we could actually transform that into a non binary matrix of implicit ratings. Let's see an example of this. So here, the implicit rating of one means they viewed a particular post, two means they liked it and three means they commented on the post. So here we would just multiply these R imps across our entire binary user item matrix. Now, typically you'll have some multiple here, which you can tune with cross validation. All right, so let's take our implicit ratings here and multiply that across our binary matrix. So now what will our loss function look like? Well, this is what we had before. Now, we just have to multiply this matrix times our implicit rating matrix. This reg over here just means all those regularization terms that we saw earlier, they're just condensed down into the single term. Now, if you remember, for linear regression, we could use a closed form solution to solve the equation called ordinary least squares. However, now that we have to optimize both of these terms instead of just one of the terms, which in the case of linear regression was W, we can't use ordinary least squares in the same way, we actually have to use something called alternating least squares, and you can find this in libraries, such as Spark ML. Alternating least squares just fixes or keeps constant one half of the values that we're solving for. So here it would keep constant U. It would perform ordinary least squares on the loss, and then it would fix P and repeat ordinary least squares on the U. It would continue this pattern in an alternating fashion, which is why it's called alternating least squares. In general, matrix factorization performs well in practice, and we can also tune the dimensions of U and P. So U and P can be any size respectively. Usually they're same size though together. How do we use this to get predictions? So here was our initial equation and the whole goal was to use alternating least squares on this side over here in order to best approximate our original user item matrix. To get a prediction for a particular user in a post, what we can do is just multiply this row I here with this column J here, include our biases, and that will give us our prediction for this user in this post. One problem with this, is that we'd have to retrain for every new customer that came in. And finally, to evaluate the performance of these predictions, you can use mean squared error on the validation set. So how can we avoid having to retrain these models for every new customer? Well, we can use something called a deep learning extension of these matrix factorizations. So in this case, the row of the user item matrix in the column of user item matrix would just be inputs to our neural network. Now, these inputs would have their own separate fully connected layers, which would act as embedding layers. We talked about embedding layers in previous videos. Then the results of these embeddings will be combined into a single, fully connected layer to finally be sent through a linear activation function, which we use for regression, and the output R here would be the prediction for a particular user and post. This typically requires less retraining. So what are some overall challenges that we have with collaborative filtering? Well, one, we have a cold-start problem. So brand new users with no information or items with no purchases or interactions, we can't generate predictions for. There are some ways to mitigate this such as recommending new users popular items or presenting new items to random subgroups in which you have some belief that they will have interest in them, but generally this will still be a problem with collaborative filtering. Second, we have to make sure that we're not creating an echo chamber of our user item matrix. Let's say that we recommend an item to a user, so that increments some of their values and that user item matrix. Now that that value has been incremented, it has more weight for other users and it just spins into this positive feedback loop of recommending potentially the same or very similar items over and over. This doesn't make for a good customer experience because these users won't see the variety that they need to see, instead, they'll be seeing the same things that they've already been recommended. To make sure we don't end up with that, we have to make sure that we introduce some form of diversity into our recommendations. This could be as simple as pitching pretty random items which are more popular in other areas. Lastly, these collaborative filtering techniques can be susceptible to something called a shilling attack. This happens in systems where everyone can provide a rating. So if I had a particular post and I wanted to make sure that post was read everywhere, I could create a bunch of accounts, like the post and then boost its likelihood of being recommended. Likewise, if I had a competitor, I could go and dislike their post, such that their posts would not appear at the top of the list. Now, there are some obvious things that we can do to mitigate this, such as allowing only one user per phone. So now that we've covered collaborative based filtering, we're going to go over something called content based filtering. Content filtering represents a user with respect to posts that they've interacted with. Let's say user one interacted with a political post, did not interact with an Amazon post, and interacted with a product release, we could then label posts based on their content. So here, post one is not political, it is about a product release. Post two is political and it's about Amazon, and post three is just political. So additionally to just use binary features that the user has, we can also apply our implicit feedback. So let's say that the user viewed political articles and they commented on product releases, all then that we have to do now is just take the dot product of the user with respect to every other post and get the maximum dot product. So here, this is one times four, which is four. We have one times two plus zeros, which is two. Here, we have two times one plus four times one, which is six. So according to this user's past history and the attributes of this particular post, this user would be recommended this particular post. So let's look at some more details of content-based filtering. One, it doesn't require any other users' data to make a prediction about a particular user. So if there's tons of users, you can use content based filtering if you want to avoid the K nearest neighbors or some sort of item-item similarity matrix. The downside though, is that it requires context about the items. For example, for the post, we had to label them as political or having to deal with Amazon, but with the collaborative based filtering methods, we didn't have to know anything about the items or the users, we just looked at their interactions. So there is a way to combine content based and collaborative based filtering methods. We're going to do this through a deep learning hybrid. So here this is going to be the same neural network that we looked at before for the deep learning extension of matrix factorization. But now we're going to condense these fully connected layers into just this. So we have the same thing as we had before, we're just representing it in a more concise manner here. And then what we're going to do is move this up a little bit so we have room, and then we're going to add these side features. So these side features are the same things that we saw in content-based filtering. So it could be attributes about past user behavior and particular tags or categories that posts would fall into. These would each have their own fully connected layers, embedding layers. And then finally they would join up to create a single response prediction for a particular user and post. In total, this deep learning hybrid that we have is similar to the deep collaborative method, which is matrix factorization, but it also includes our side features. So what are we going to use for our particular recommendation system when it comes to deciding whether or not we should send a push notification to users based on the content that has been written by our content creators? Well, we're actually going to use matrix factorization. Our implicit features here are going to be one through four, which we already talked about before. Our alpha or our waiting on these implicit features is going to be 40, otherwise in this matrix, the value will be zero. U and P, and this matrix factorization are going to have 10 dimensions or latent factors. Finally, we use Spark ML as our library. So the results of our model was that we had a click rate or a push notification open rate of 9.4%. This is compared to the 4.9% opening rate of our push notifications when we just recommended trending posts. So we would consider this model a success because we've almost doubled our push notification opening rate. All right, well that wraps it up for this video. Thanks for joining and join us next video as we continue our machine learning journey.